{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession.builder\n",
    "                .appName(\"Stack Overflow Data Wrangling\")\n",
    "                .getOrCreate()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data\n",
    "questions = spark.read.csv(\"questions.csv\", header=True,\n",
    "                          inferSchema=True, escape='\"', multiLine=True)\n",
    "\n",
    "answers = spark.read.csv(\"answers.csv\", header=True,\n",
    "                          inferSchema=True, escape='\"', multiLine=True)\n",
    "\n",
    "users = spark.read.csv(\"users.csv\", header=True,\n",
    "                          inferSchema=True, escape='\"', multiLine=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for repeating columns of all_Data in companies and rename by adding all_data\n",
    "\n",
    "for answers_col in answers.columns:\n",
    "    if answers_col in questions.columns + users.columns:\n",
    "        answers = answers.withColumnRenamed(answers_col, answers_col + \"_\" + 'answers')\n",
    "for questions_col in questions.columns:\n",
    "    if questions_col in answers.columns + users.columns:\n",
    "        questions = questions.withColumnRenamed(questions_col, questions_col + \"_\" + 'questions')\n",
    "for users_col in users.columns:\n",
    "    if users_col in questions.columns + answers.columns:\n",
    "        users = users.withColumnRenamed(users_col, users_col + \"_\" + 'users')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_country(col):\n",
    "    '''\n",
    "    This function loops through each record in the applied column and checks if its \n",
    "    netherlands and returns\n",
    "    it\n",
    "    '''\n",
    "    for word in col.split(','):\n",
    "        if \"Netherlands\" in word:\n",
    "            return word\n",
    "def return_city(col):\n",
    "    '''\n",
    "    This function loops through each record in the applied column and checks if there is no netherlands\n",
    "    returns only the city part\n",
    "    it\n",
    "    '''\n",
    "    for word in col.split(','):\n",
    "        if not 'Netherlands' in word:\n",
    "            return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "udf_return_country = udf(return_country, StringType())\n",
    "udf_return_city = udf(return_city, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.createOrReplaceTempView('new_users')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------+\n",
      "|location                                      |\n",
      "+----------------------------------------------+\n",
      "|Driebergen, Driebergen-Rijsenburg, Netherlands|\n",
      "|Amsterdam, Netherlands                        |\n",
      "|Netherlands                                   |\n",
      "|Netherlands                                   |\n",
      "|Netherlands                                   |\n",
      "|Netherlands                                   |\n",
      "|Amsterdam, Netherlands                        |\n",
      "|The Netherlands                               |\n",
      "|Amsterdam, Netherlands                        |\n",
      "|Rotterdam, Netherlands                        |\n",
      "|Netherlands                                   |\n",
      "|Eindhoven, Netherlands                        |\n",
      "|Netherlands                                   |\n",
      "|Netherlands                                   |\n",
      "|Amstelveen, Netherlands                       |\n",
      "|Netherlands                                   |\n",
      "|The Netherlands                               |\n",
      "|Netherlands                                   |\n",
      "|Amsterdam, Netherlands                        |\n",
      "|Roermond, Netherlands                         |\n",
      "+----------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_users = spark.sql(\"SELECT * FROM new_users WHERE location LIKE '%Netherlands%'\")\n",
    "new_users.select('location').show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the country from location with the return_country function\n",
    "new_users = new_users.withColumn(\"country\", udf_return_country(\"location\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the city from location with the return_city function\n",
    "new_users = new_users.withColumn(\"city\", udf_return_city(\"location\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'display_name',\n",
       " 'reputation',\n",
       " 'website_url',\n",
       " 'location',\n",
       " 'about_me',\n",
       " 'views',\n",
       " 'up_votes',\n",
       " 'down_votes',\n",
       " 'image_url',\n",
       " 'created_at',\n",
       " 'updated_at',\n",
       " 'country',\n",
       " 'city']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_users.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Join the users dataframe with the questions dataframe \n",
    "joined_df = new_users.join(questions, new_users['id'] == questions['user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter out only records with view_count 20 or more\n",
    "joined_df = joined_df.filter(col('view_count') >= 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Join the resulting dataframe with the answers dataframe\n",
    "results = joined_df.join(answers, joined_df['user_id'] == answers['user_id_answers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------+-------+---------------+\n",
      "|         updated_at|view_count|user_id|user_id_answers|\n",
      "+-------------------+----------+-------+---------------+\n",
      "|2019-10-12 18:32:46|       576|7666972|        7666972|\n",
      "|2019-08-05 14:34:28|       145| 555132|         555132|\n",
      "|2019-03-16 12:30:45|        69|2548426|        2548426|\n",
      "|2019-10-10 13:13:07|        32|5798882|        5798882|\n",
      "|2019-10-10 13:13:07|        32|5798882|        5798882|\n",
      "+-------------------+----------+-------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Lets take a look at the final dataframe\n",
    "results.select('updated_at', 'view_count', 'user_id', 'user_id_answers').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|    min(updated_at)|\n",
      "+-------------------+\n",
      "|2019-02-01 13:54:00|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#return the minimum updated_at time.\n",
    "results.select(F.min('updated_at')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'display_name',\n",
       " 'reputation',\n",
       " 'website_url',\n",
       " 'location',\n",
       " 'about_me',\n",
       " 'views',\n",
       " 'up_votes',\n",
       " 'down_votes',\n",
       " 'image_url',\n",
       " 'created_at',\n",
       " 'updated_at',\n",
       " 'country',\n",
       " 'city',\n",
       " 'id_questions',\n",
       " 'user_id',\n",
       " 'title',\n",
       " 'body',\n",
       " 'accepted_answer_id',\n",
       " 'score',\n",
       " 'view_count',\n",
       " 'comment_count',\n",
       " 'created_at_questions',\n",
       " 'id_answers',\n",
       " 'user_id_answers',\n",
       " 'question_id',\n",
       " 'body_answers',\n",
       " 'score_answers',\n",
       " 'comment_count_answers',\n",
       " 'created_at_answers']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unexpected type: <class 'type'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-7e8b9ef76734>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"updated_at\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"updated_at\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDateType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/blossom/spark-3.0.1-bin-hadoop2.7/python/pyspark/sql/column.py\u001b[0m in \u001b[0;36mcast\u001b[0;34m(self, dataType)\u001b[0m\n\u001b[1;32m    600\u001b[0m             \u001b[0mjc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjdt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"unexpected type: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unexpected type: <class 'type'>"
     ]
    }
   ],
   "source": [
    "#results.withColumn(\"updated_at\", col(\"updated_at\").cast(DateType)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.write.format(\"jdbc\").options(\n",
    "    url='jdbc:postgresql://localhost/postgres',\n",
    "    driver='org.postgresql.Driver',\n",
    "    user='postgres',\n",
    "    password='postgres',\n",
    "    dbtable='stackoverflow_filtered.results'\n",
    ").save(mode='append')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
